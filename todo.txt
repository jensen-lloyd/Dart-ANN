- store outputs at every layer of the network during forward pass for use later in backprop

- create inverse activation functions 

- backprop

- add more loss functions

- tidy up function parameter names (e.g. networkArray vs layersArray)

- add more activation functions (sigmoid, tanH)

